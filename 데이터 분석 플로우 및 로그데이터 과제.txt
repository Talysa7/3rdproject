 {
  log_type : 1~10,		//  ( 1 : 검색 , 2 : 상세검색 ,3 : 글쓰기 , 4 : 코멘트 , 5: 평판작성 , 6 : 로그인  , 7 :개인정보수정 그밖에 필요한 것 추가 가능) 
  result : {
	user_id : user_id,
	board_id : [ ] ,
 		....
	필요한 정보들 전부 저장.
	}
 }

이렇게 싸서 DB에 logTable에 저장 ( logTable은 두개의 컬럼 한개는 PK, 한개는 제이슨 문자열  (VARCHAR) 로 3천칸짜리 칸을 가진 DB로 한다)

이후 crone으로 일정시간마다 데이터 전처리하는 jar파일을 실행 데이터를 분해 -> 

로그별로 따로 파일을 생성 ( type1.csv , type2.csv 이런식으로)

이후 flume으로 필요사항만(현재 구상중인 서비스에는 1,2,3,4 정도만 필요할듯? 서비스 추가시 다른 로그도 필요할 가능성 농후) 적재.  -> 파이썬이나 스파크로 분석 후, 분석 결과를 sqoop으로 mariaDB resultTable에 저장. 

사이트에서 서비스시에는 resultTable의 결과를 사용한다.

